{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA) of a Pruvo dataset.\n",
    "\n",
    "## Instructions:\n",
    "Let me share with you a sample of the data we do have on our end and let me know what you think.\n",
    "\n",
    "During the last years we were collecting a lot of human decisions regarding the relations of 2 room types.\n",
    "\n",
    "In the following excel: https://docs.google.com/spreadsheets/d/1AjDaqnXrZFy3KAspjUAVo5cLt37MEVXOuBooYDM9Kr8/edit?usp=sharing\n",
    "\n",
    "You can see the decisions made between the original room type (Col A) and the proposed one (Col B).\n",
    "\n",
    "Links = how many times a person clicked that both rooms in A and B are the same (if it is higher than 6 it means someone put a \"force\" match decision – this is the admin 1000 score you see)\n",
    "\n",
    "Unlinks = how many times someone decided it is not a match (different room type)\n",
    "\n",
    "Score = links – unlinks + admin\n",
    "\n",
    "I think we have a few millions of rows like that (of course that there are mistakes there as it was a human decision)\n",
    "\n",
    "Let me know what you think…\n",
    "\n",
    "## Initial Reflections, Implicit/Explicit Relations & Assumptions\n",
    "It seems that in the dataset I'm about to analyse there are 2 columns (A & B), A being the original, B being the one proposed by Pruvo, then a third column called \"Links\" that scores how well column A & B are related by, and this is ambiguous: \"how many times a person clicked that both rooms [columns] are the same\", which I'm taking it to mean that several individuals, each one time, indicated that these columns (A & B) either refer in fact to the same room, or that they do not by selecting to unlink, which is represented by the next column.\n",
    "\n",
    "Also to note that if the the number in the \"Links\" column is higher than 6 (was it meant \"6 or higher\"?), then someone \"put a force match decision\", being accompanied by a final column called \"admin\" with the value of 1_000, which I'm taking to mean that someone forcibly marked Col A & B has being the same.\n",
    "\n",
    "These assumptions being correct, I'd deduce that this is a synthetic dataset, in the sense that it was generated to create an algorithm, where 6 evaluators looked at each datapoint couple of column A & B, and in a binary selection indicated whether they're referring to the same object, in this case hotel room, or not, with 6 being the higher degree of agreement between the 6 evaluators (they all agree it's the same room) and 0 the lowest (they all agree it's a different room), or something in between.\n",
    "\n",
    "At the same time, with this assumption, the admin score should refer to an overseer that knows if the two columns refer to the same room or not and has entered a number higher than 6 on the links and 1_000 on the admin to control that indeed there's no mistake in the data. This would be a somewhat standard way of establishing a human-level performance (or technically speaking a Bayes Error Rate) that could be useful to establish an expectation of the algorithm performance (but at this moment doesn't seem to make much sense).\n",
    "\n",
    "This deduction makes in fact little sense, has the score wouldn't require the deduction of the unlinks from the links to reflect it's confidence, and the adding of the admin score to 1_000 (assuming there's no other value in said column) would massively bias the confidence score of any algorithm I can think of the top of my head, has anything with a score that not even close to 1_000 would be considered awful by the algorithm, 'though a score of 1_001 would be almost as good as a score of 6 (with my assumption), but the algorithm would become so biased it should reject that score.\n",
    "\n",
    "I'll need to look at the data and try to make more sense out of this.\n",
    "\n",
    "## Initial Plan\n",
    "Before even having loaded the data, the plan passes by loading the data, doing an EDA on the data, clarifying any doubts I might have (including the doubts above) and moving on from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pruvo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a4e6fcf95514680bc5f83daad137e1a6dcae525ba08020e51c8a183e22e2ac65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
